#!/usr/bin/env python3
"""
Test Example: Enhanced Legal Agent Integration
Demonstrates how the enhanced legal agent processes queries with training data
"""

import asyncio
import logging
import json
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_enhanced_legal_agent_integration():
    """
    Test the enhanced legal agent integration with training data
    """
    print("üîÑ Testing Enhanced Legal Agent Integration with Training Data")
    print("=" * 60)
    
    # Test queries that should utilize training data
    test_queries = [
        {
            "query": "How do I file a complaint against my landlord for not returning security deposit?",
            "expected_data_types": ["procedure", "case_law", "fees"],
            "urgency": "medium"
        },
        {
            "query": "What are the court fees for filing a civil suit in Delhi?",
            "expected_data_types": ["fees", "geographical_jurisdiction"],
            "urgency": "low"
        },
        {
            "query": "I need to file an emergency petition for bail. Help me urgently!",
            "expected_data_types": ["emergency_data", "procedure", "court_hierarchy"],
            "urgency": "high"
        }
    ]
    
    print("üìä Test Scenarios:")
    for i, test_case in enumerate(test_queries, 1):
        print(f"\n{i}. Query: {test_case['query']}")
        print(f"   Expected Data Types: {', '.join(test_case['expected_data_types'])}")
        print(f"   Urgency Level: {test_case['urgency']}")
        
        # Simulate processing flow
        print(f"   Processing Flow:")
        print(f"   ‚îú‚îÄ üì• Input Processing & Validation")
        print(f"   ‚îú‚îÄ üîç Enhanced Legal Agent (RAG + Gemma3)")
        print(f"   ‚îÇ  ‚îú‚îÄ Vector search across training data")
        print(f"   ‚îÇ  ‚îú‚îÄ Context retrieval from {', '.join(test_case['expected_data_types'])}")
        print(f"   ‚îÇ  ‚îú‚îÄ Gemma3 local model processing")
        print(f"   ‚îÇ  ‚îî‚îÄ Quality assessment & confidence scoring")
        print(f"   ‚îú‚îÄ üìä Quality-based routing decision")
        print(f"   ‚îú‚îÄ ü§ñ Agent enhancement (if needed)")
        print(f"   ‚îî‚îÄ üì§ Response assembly & delivery")
    
    print("\n" + "=" * 60)
    print("üéØ Integration Benefits:")
    print("‚úÖ Local training data utilization")
    print("‚úÖ Gemma3 model for legal reasoning")
    print("‚úÖ Context-aware response generation")
    print("‚úÖ Quality-based enhancement routing")
    print("‚úÖ Graceful fallback mechanisms")
    
    print("\nüìà Expected Response Quality Factors:")
    print("‚Ä¢ Legal terminology usage")
    print("‚Ä¢ Case law references from training data")
    print("‚Ä¢ Actionable procedural guidance")
    print("‚Ä¢ Relevant fee information")
    print("‚Ä¢ Court hierarchy awareness")
    print("‚Ä¢ Location-specific jurisdiction info")
    
    print("\nüîß Configuration Requirements:")
    print("‚Ä¢ Ollama running with Gemma3 model")
    print("‚Ä¢ Training data loaded in Database/training_data/")
    print("‚Ä¢ Vector embeddings indexed in ChromaDB")
    print("‚Ä¢ Environment variables configured in .env")
    
    return True

async def demo_rag_processing_flow():
    """
    Demonstrate the RAG processing flow with training data
    """
    print("\nüß† RAG Processing Flow Demonstration")
    print("=" * 50)
    
    # Simulate RAG processing steps
    steps = [
        {
            "step": "1. Query Analysis",
            "description": "Parse user query and extract legal concepts",
            "example": "Query: 'file complaint landlord' ‚Üí Concepts: [tenant_rights, complaint_filing, property_law]"
        },
        {
            "step": "2. Vector Search",
            "description": "Search training data using embeddings",
            "example": "Search results: 5 case_law docs, 3 procedure docs, 2 fee docs (similarity > 0.7)"
        },
        {
            "step": "3. Context Assembly",
            "description": "Combine relevant training data as context",
            "example": "Context: 1500 tokens from case precedents + filing procedures + fee structure"
        },
        {
            "step": "4. Gemma3 Processing",
            "description": "Generate response using local model + context",
            "example": "Input: Query + Context ‚Üí Gemma3 ‚Üí Legal analysis + recommendations"
        },
        {
            "step": "5. Quality Assessment",
            "description": "Evaluate response completeness and accuracy",
            "example": "Score: 0.85 (high quality) ‚Üí Use as primary response"
        },
        {
            "step": "6. Enhancement Decision",
            "description": "Decide on agent enhancement needs",
            "example": "High quality ‚Üí Add interactive elements only"
        }
    ]
    
    for step_info in steps:
        print(f"\n{step_info['step']}")
        print(f"‚îú‚îÄ {step_info['description']}")
        print(f"‚îî‚îÄ {step_info['example']}")
    
    print("\nüìä Quality Metrics:")
    quality_metrics = {
        "content_completeness": "85%",
        "legal_terminology": "90%", 
        "actionable_guidance": "80%",
        "case_law_references": "75%",
        "source_diversity": "3 types",
        "overall_confidence": "0.82"
    }
    
    for metric, value in quality_metrics.items():
        print(f"‚Ä¢ {metric.replace('_', ' ').title()}: {value}")
    
    return True

async def show_training_data_structure():
    """
    Show the training data structure and types
    """
    print("\nüìÅ Training Data Structure")
    print("=" * 40)
    
    data_structure = {
        "case_law/": {
            "description": "Legal precedents and court judgments",
            "files": "*.json",
            "content": "case_name, court, facts, judgment, legal_reasoning, precedents"
        },
        "procedure/": {
            "description": "Legal procedures and filing processes",
            "files": "*.json", 
            "content": "step-by-step guides, required documents, timelines"
        },
        "court_hierarchy.json": {
            "description": "Court structure and jurisdictions",
            "files": "single file",
            "content": "court levels, appeal processes, jurisdiction mappings"
        },
        "emergency_data/": {
            "description": "Urgent legal matter handling",
            "files": "*.json",
            "content": "emergency procedures, urgent contacts, time-sensitive processes"
        },
        "Fees/": {
            "description": "Court fees and legal costs",
            "files": "*.json",
            "content": "filing fees, court costs, payment schedules by jurisdiction"
        },
        "geographical_jurisdiction/": {
            "description": "Location-based legal information",
            "files": "*.json",
            "content": "jurisdiction boundaries, local courts, regional procedures"
        }
    }
    
    for path, info in data_structure.items():
        print(f"\nüìÇ {path}")
        print(f"   Description: {info['description']}")
        print(f"   Files: {info['files']}")
        print(f"   Content: {info['content']}")
    
    print(f"\nüîç Vector Indexing:")
    print(f"‚Ä¢ Embedding Model: all-MiniLM-L6-v2")
    print(f"‚Ä¢ Chunk Size: 1000 tokens")
    print(f"‚Ä¢ Chunk Overlap: 200 tokens")
    print(f"‚Ä¢ Top-K Retrieval: 5 documents")
    print(f"‚Ä¢ Similarity Threshold: 0.7")
    
    return True

async def main():
    """Main test function"""
    print("üöÄ Enhanced Legal Agent Integration Test")
    print("Using training data + Ollama Gemma3 model")
    print("=" * 70)
    
    # Run test scenarios
    await test_enhanced_legal_agent_integration()
    await demo_rag_processing_flow()
    await show_training_data_structure()
    
    print("\n" + "=" * 70)
    print("‚úÖ Enhanced Legal Agent Integration Test Complete!")
    print("üîß To run the actual system:")
    print("   1. Ensure Ollama is running: `ollama serve`")
    print("   2. Pull Gemma3 model: `ollama pull gemma3`")
    print("   3. Start the AI model service: `python start.py`")
    print("   4. The enhanced legal agent will automatically initialize")
    print("   5. Training data will be indexed on first startup")

if __name__ == "__main__":
    asyncio.run(main())
